{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEunG/bv0UFWbr+2yitlRo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darinkist/Enhancing_LLMs_with_Search_APIs/blob/main/MediumArticle_Enhancing_LLMs_with_Search_APIs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ubhlnh6EJW1X"
      },
      "outputs": [],
      "source": [
        "!pip install -q exa_py tavily-python langchain langchainhub langchain-openai llama-index llama-index-llms-langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from tavily import TavilyClient\n",
        "from langchain.tools import tool\n",
        "import json\n",
        "\n",
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "from langchain.agents.format_scratchpad.openai_tools import (\n",
        "    format_to_openai_tool_messages,\n",
        ")\n",
        "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.agents.format_scratchpad.openai_tools import (\n",
        "    format_to_openai_tool_messages,\n",
        ")\n",
        "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
        "from llama_index.core.evaluation import RelevancyEvaluator\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "OHedCCWqJeY3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YOU.COM API\n",
        "@tool\n",
        "def you_com_api(query: str) -> str:\n",
        "  \"\"\"Use this tool to search for latest information on the internet.\"\"\"\n",
        "  headers = {\"X-API-Key\": \"XXXX\"}\n",
        "  params = {\"query\": query, \"num_web_results\":3}\n",
        "  results = requests.get(\n",
        "        f\"https://api.ydc-index.io/search\",\n",
        "        params=params,\n",
        "        headers=headers,\n",
        "  ).json()\n",
        "  return json.dumps(results)\n",
        "\n",
        "\n",
        "# Exa Search API\n",
        "@tool\n",
        "def exa_search_api(query: str) -> str:\n",
        "  \"\"\"Use this tool to search for latest information on the internet.\"\"\"\n",
        "  url = \"https://api.exa.ai/search\"\n",
        "\n",
        "  payload = { \"query\": query, \"contents\": { \"text\": { \"includeHtmlTags\": False } }, \"numResults\": 3 }\n",
        "  headers = {\n",
        "      \"accept\": \"application/json\",\n",
        "      \"content-type\": \"application/json\",\n",
        "      \"x-api-key\": \"XXX\"\n",
        "  }\n",
        "  response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "  return response.text\n",
        "\n",
        "\n",
        "# Tavily Search\n",
        "@tool\n",
        "def tavily_search_api(query: str) -> str:\n",
        "  \"\"\"Use this tool to search for latest information on the internet.\"\"\"\n",
        "  tavily = TavilyClient(api_key=\"tvly-XXX\")\n",
        "  result = tavily.search(query=query,\n",
        "                        search_depth=\"advanced\",\n",
        "                        max_results=3,\n",
        "                        include_answer = True,\n",
        "                        include_raw_content=False)\n",
        "  return json.dumps(result)\n",
        "\n",
        "\n",
        "# Perplexity AI\n",
        "@tool\n",
        "def perplexity_ai_api(query: str) -> str:\n",
        "  \"\"\"Use this tool to search for latest information on the internet.\"\"\"\n",
        "  url = \"https://api.perplexity.ai/chat/completions\"\n",
        "\n",
        "  payload = {\n",
        "      \"model\": \"sonar-medium-online\",\n",
        "      \"messages\": [\n",
        "          {\n",
        "              \"role\": \"system\",\n",
        "              \"content\": \"Be precise and concise.\"\n",
        "          },\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": query\n",
        "          }\n",
        "      ]\n",
        "  }\n",
        "  headers = {\n",
        "      \"accept\": \"application/json\",\n",
        "      \"content-type\": \"application/json\",\n",
        "      \"authorization\": \"Bearer pplx-XXX\"\n",
        "  }\n",
        "\n",
        "  response = requests.post(url, json=payload, headers=headers)\n",
        "  return response.text"
      ],
      "metadata": {
        "id": "owWD7jE5JfdB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare agent\n",
        "# Following https://python.langchain.com/docs/modules/agents/agent_types/openai_tools\n",
        "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
        "\n",
        "\n",
        "def ask_agent(query, tool):\n",
        "\n",
        "  # Bind tools to agent\n",
        "  llm = ChatOpenAI(openai_api_key=\"XXX\",\n",
        "                   model=\"gpt-4-0125-preview\",\n",
        "                   temperature=0)\n",
        "  llm_agent = llm.bind_tools([tool])\n",
        "\n",
        "  # Define proper promt that includes tools\n",
        "  prompt = ChatPromptTemplate.from_messages(\n",
        "      [\n",
        "          (\n",
        "              \"system\",\n",
        "              \"\"\"You are very powerful assistant, but don't know current events.\n",
        "              Always try to list the sources your answer is based on.\n",
        "              \"\"\",\n",
        "          ),\n",
        "          (\"user\", \"{input}\"),\n",
        "          MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  # Assembling llm and parts to get an agent\n",
        "  agent = (\n",
        "      {\n",
        "          \"input\": lambda x: x[\"input\"],\n",
        "          \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
        "              x[\"intermediate_steps\"]\n",
        "          ),\n",
        "      }\n",
        "      | prompt\n",
        "      | llm_agent\n",
        "      | OpenAIToolsAgentOutputParser()\n",
        "  )\n",
        "  agent_executor = AgentExecutor(agent=agent, tools=[tool], verbose=True)\n",
        "  result = agent_executor.invoke({\"input\": query})\n",
        "  return result[\"output\"]"
      ],
      "metadata": {
        "id": "OgYIoBFbJpxZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_service(query:str, agent_answer: str) -> dict:\n",
        "  output_parser = StrOutputParser()\n",
        "  instruction = \"\"\"\n",
        "  The current year is 2024.\n",
        "\n",
        "  # Task:\n",
        "  - Assess whether the AI's response adequately addresses the user's query provided below.\n",
        "\n",
        "  # Instructions:\n",
        "  1. Carefully read the user's query.\n",
        "  2. Thoroughly review the AI's response.\n",
        "  3. Rate on a scale from 1 to 5 the level of detail in the answer.\n",
        "  4. Rate on a scale from 1 to 5 how up-to-date the information in the answer is, considering the date of the sources if provided.\n",
        "  5. Rate on a scale from 1 to 5 the overall quality of the answer.\n",
        "\n",
        "  # Evaluation Criteria:\n",
        "  - **Detail Level:** Assess how thoroughly the answer addresses the query, considering all relevant aspects.\n",
        "  - **Up-to-date Information:** Evaluate the currency and relevance of the information provided in the answer, taking into account the date of sources if provided.\n",
        "  - **Answer Quality:** Judge the overall quality of the response, including accuracy, coherence, and relevance.\n",
        "\n",
        "  # Options:\n",
        "  - Choose one of the following:\n",
        "    - \"YES\": If the AI's response effectively addresses the user's query, providing relevant and accurate information.\n",
        "    - \"NO\": If the AI's response does not sufficiently address the user's query or is unrelated.\n",
        "\n",
        "  # Return Format:\n",
        "  - Provide your answer in JSON format with the keys:\n",
        "    - \"ANSWER\": \"YES\" or \"NO\"\n",
        "    - \"DETAIL_RATING\": (1-5)\n",
        "    - \"UP_TO_DATE_RATING\": (1-5)\n",
        "    - \"QUALITY_RATING\": (1-5)\n",
        "    - \"REASONING\": Explain your ratings for each criterion.\n",
        "\n",
        "  # User's Query:\n",
        "  {query}\n",
        "\n",
        "  # AI's Response:\n",
        "  {model_answer}\n",
        "  \"\"\"\n",
        "\n",
        "  prompt = PromptTemplate(\n",
        "      template=instruction,\n",
        "      input_variables=[\"query\", \"model_answer\"]\n",
        "  )\n",
        "\n",
        "  gpt3 = ChatOpenAI(temperature=0,\n",
        "                    model=\"gpt-4\",\n",
        "                    openai_api_key=\"XXX\")\n",
        "\n",
        "  chain = prompt | gpt3 | output_parser\n",
        "  eval = chain.invoke({\"query\": query, \"model_answer\":agent_answer})\n",
        "  return json.loads(eval)"
      ],
      "metadata": {
        "id": "aoNvtBRGJr3h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    \"What are the top marketing trends in 2024?\",\n",
        "    \"What are some significant geopolitical events that have occurred in February 2024?\",\n",
        "    \"Could you summarize the most recent developments in artificial intelligence research and breakthroughs?\",\n",
        "    \"What is the latest unemployment rate in the United States as reported by the Bureau of Labor Statistics?\"\n",
        "    ]\n",
        "\n",
        "tools = [you_com_api, exa_search_api, tavily_search_api, perplexity_ai_api]"
      ],
      "metadata": {
        "id": "ZqRJ9XkIJujf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = {}\n",
        "for tool in tools:\n",
        "    ratings[tool.get_name()] = {}\n",
        "    for q in questions:\n",
        "        try:\n",
        "            # time.sleep(2)\n",
        "            tmp_answer = ask_agent(q, tool)\n",
        "            if tmp_answer is not None:\n",
        "                ratings[tool.get_name()][q] = eval_service(q, tmp_answer)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while processing {q} with {tool}: {e}\")"
      ],
      "metadata": {
        "id": "CffKbGNQJwVt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}